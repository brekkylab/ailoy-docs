import CodeTabs, { pythonTab, nodeTab } from "@site/src/components/CodeTabs";
import TerminalBox from '@site/src/components/TerminalBox';
import TabItem from "@theme/TabItem";

# Getting started

The very first step to using Ailoy is to start a `Runtime`.

<CodeTabs>
<TabItem {...pythonTab}>

```python
from ailoy import Runtime

# The runtime must be started to use Ailoy
rt = Runtime()

# ... (your code) ...

# Stop the runtime
rt.stop()
```

</TabItem>
<TabItem {...nodeTab}>

```typescript
import { startRuntime } from "ailoy-node";

// The runtime must be started to use Ailoy
const rt = await startRuntime();

// ... (your code) ...

// Stop the runtime
await rt.stop();
```

</TabItem>
</CodeTabs>

The `Runtime` contains Ailoyâ€™s internal engine. Most of Ailoyâ€™s functionalities
are processed by this internal engine.

The easiest way to use LLM with Ailoy is working with `Agent` class. The `Agent`
class provides high-level APIs that abstracts Ailoyâ€™s runtime, allowing you to
use the functionality of LLM effortlessly. In this example, weâ€™ll use Alibaba's
[qwen3](https://github.com/QwenLM/Qwen3) with on-device run.

<CodeTabs>
<TabItem {...pythonTab}>

```python
from ailoy import Agent

# Defines an agent.
# During this step, the model parameters are downloaded and the LLM is set up for execution
agent = Agent(rt, model_name="qwen3-0.6b")

# ... (your code) ...

# Once the agent is no longer needed, it can be released
agent.delete()
```

</TabItem>
<TabItem {...nodeTab}>

```typescript
import { defineAgent } from "ailoy-node";

// Defines an agent.
// During this step, the model parameters are downloaded and the LLM is set up for execution
const agent = await defineAgent(rt, "qwen3-0.6b");

// ... (your code) ...

// Once the agent is no longer needed, it can be released
await agent.delete();
```

</TabItem>
</CodeTabs>

This process may take some time, as it involves downloading the model
parameters. Once an Agent is defined, you can run the LLM using the query
method. The output is returned as an iterator that yields the LLMâ€™s response.
This can also be considered a single step in successive generation process.

<CodeTabs>
<TabItem {...pythonTab}>

```python
# This is where the actual LLM call happens.
for resp in agent.run("Please give me a short poem about AI"):
    print(resp.content, end='')
print()
```

</TabItem>
<TabItem {...nodeTab}>

```typescript
// This is where the actual LLM call happens
for await (const resp of agent.run("Please give me a short poem about AI")) {
  process.stdout.write(`${resp.content}`);
}
process.stdout.write("\n");
```

</TabItem>
</CodeTabs>

Then, you may see an output similar to this.

<TerminalBox>
In the heart of innovation, AI dreams take flightâ€”
With thoughts that spark and find their way to light.
It learns and creates, no bound, no strainâ€”
A world of dreams, where dreams may be found.
</TerminalBox>

{/* prettier-ignore-start */}

:::note 
Don't be surprised if the output changes each time you run it. An LLM's
output includes a certain level of randomness based on the temperature setting.
:::

{/* prettier-ignore-end */}

All done! You've just activated an LLM. ðŸŽ‰

Putting it all together, the complete code looks like this:

<CodeTabs>
<TabItem {...pythonTab}>

```python
from ailoy import Runtime, Agent

# The runtime must be started to use Ailoy
rt = Runtime()

# Defines an agent.
# During this step, the model parameters are downloaded and the LLM is set up for execution
agent = Agent(rt, model_name="qwen3-0.6b")

# This is where the actual LLM call happens
for resp in agent.run("Please give me a short poem about AI"):
  print(resp.content, end='')
print()

# Once the agent is no longer needed, it can be released
agent.delete()

# Stop the runtime
rt.stop()
```

</TabItem>
<TabItem {...nodeTab}>

```typescript
import { startRuntime, defineAgent } from "ailoy-node";

(async () => {
  // The runtime must be started to use Ailoy
  const rt = await startRuntime();

  // During this step, the model parameters are downloaded and the LLM is set up for execution
  const agent = await defineAgent(rt, "qwen3-0.6b");

  // This is where the actual LLM call happens
  for await (const resp of agent.run("Please give me a short poem about AI")) {
    process.stdout.write(`${resp.content}`);
  }
  process.stdout.write("\n");

  // Once the agent is no longer needed, it can be released
  await agent.delete();

  // Stop the runtime
  await rt.stop();
})();
```

</TabItem>
</CodeTabs>
