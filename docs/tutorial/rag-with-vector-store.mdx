import CodeTabs, { pythonTab, nodeTab } from "@site/src/components/CodeTabs";
import TabItem from "@theme/TabItem";

# RAG with Vector Store

**Retrieval-Augmented Generation (RAG)** is a useful method when you want to
use AI with your own documents. In RAG, the AI model gets extra knowledge from
outside sources, usually stored in something called a vector store. Instead of
depending only on what the model learned during training, RAG finds and adds
related documents at the time you ask a question. This helps the AI give more
accurate, up-to-date, and relevant answers.

In this example, weâ€™ll walk you through a complete RAG workflow â€” how to build
a vector store(`VectorStore`) and integrate it to the `Agent`.

### Initializing a Vector Store

Ailoy simplifies the construction of RAG pipelines through its built-in
`VectorStore` component, which works alongside the `Agent`.

To initialize a vector store:

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
from ailoy import Runtime
from ailoy.vectorstore import VectorStore, FAISSConfig

rt = Runtime() with VectorStore(rt, FAISSConfig(embedding="bge-m3")) as vs:
    ...
```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
import { createRuntime, VectorStore } from "ailoy-node";

const rt = await createRuntime();
const vs = new VectorStore(rt, {
  type: "faiss",
  embedding: "bge-m3",
});
await vs.initialize();
```

</TabItem>
</CodeTabs>

> Ailoy currently supports both
> [**FAISS**](https://github.com/facebookresearch/faiss) and
> [**ChromaDB**](https://www.trychroma.com/) as vector store backends. Refer to
> the official configuration guide for backend-specific options.

> ðŸ’¡ **Note:** At this time, the only supported embedding model is
> [`bge-m3`](https://huggingface.co/BAAI/bge-m3). Additional embedding models
> will be supported in future releases.

### Inserting Documents into the Vector Store

You can insert text along with optional metadata into the vector store:

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
vs.insert(
    "Ailoy is a lightweight library for building AI applications",
    metadata={"topic": "Ailoy"}
)
```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
await vs.insert({
  document: "Ailoy is a lightweight library for building AI applications",
  metadata: {
    topic: "Ailoy",
  },
});
```

</TabItem>
</CodeTabs>

In practice, you should split large documents into smaller chunks before
inserting them. This improves retrieval quality. You may use any text-splitting
tool (e.g.,
[LangChain](https://python.langchain.com/docs/concepts/text_splitters/)), or
utilize Ailoyâ€™s low-level runtime API for text splitting. (See
[Calling Low-Level APIs](./calling-low-level-apis.md) for more details.)

### Retrieving Relevant Documents

To retrieve documents similar to a given query:

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
query = "What is Ailoy?"
items =vs.retrieve(query, top_k=5)
```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
const query = "What is Ailoy?";
const items = await vs.retrieve(query, 5);
```

</TabItem>
</CodeTabs>

This returns a list of `VectorStoreRetrieveItem` instances representing the most
relevant chunks, ranked by similarity. The number of results is controlled via
the `top_k` parameter (default is 5).

### Constructing an Augmented Prompt

Once documents are retrieved, you can construct a context-enriched prompt as
follows:

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
prompt = f"""
    Based on the provided contexts, try to answer user's question.
    Context: {[item.document for item in items]}
    Question: {query}
"""
```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
const prompt = `
  Based on the provided contexts, try to answer user' question.
  Context: ${items.map((item) => item.document)}
  Question: ${query}
`;
```

</TabItem>
</CodeTabs>

You can then pass this prompt to the agent for inference:

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
for resp in agent.run(prompt):
    print(resp.content, end='')
print()
```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
for await (const resp of agent.run(prompt)) {
  process.stdout.write(resp.content);
}
process.stdout.write("\n");
```

</TabItem>
</CodeTabs>

### Complete Example

<CodeTabs>
<TabItem {...pythonTab}>

```python showLineNumbers
from ailoy import Runtime
from ailoy.vectorstore import VectorStore, FAISSConfig

# Initialize Runtime

rt = Runtime()

# Initialize Agent and VectorStore

with Agent(rt, model_name="qwen3-8b") as agent, VectorStore(rt, FAISSConfig(embedding="bge-m3")) as vs:
    # Insert items
    vs.insert(
        "Ailoy is a lightweight library for building AI applications",
        metadata={"topic": "Ailoy"}
    )

    # Search the most relevant items
    query = "What is Ailoy?"
    items = vs.retrieve(query)

    # Augment user query
    prompt = f"""
        Based on the provided contexts, try to answer user's question.
        Context: {[item.document for item in items]}
        Question: {query}
    """

    # Invoke agent
    for resp in agent.run(prompt):
        print(resp.content, end='')
    print()

```

</TabItem>
<TabItem {...nodeTab}>

```typescript showLineNumbers
import { createRuntime, createAgent, createVectorStore } from "ailoy-node";

async function main() {
  // Initialize Runtime
  const rt = await createRuntime();
  // Initialize Agent
  const agent = await createAgent(rt, { model: { name: "qwen3-8b" } });
  // Initialize VectorStore
  const vs = await createVectorStore(rt, {
    type: "faiss",
    embedding: "bge-m3",
  });

  // Insert items
  await vs.insert({
    document: "Ailoy is a lightweight library for building AI applications",
    metadata: { topic: "Ailoy" },
  });

  // Search the most relevant items
  const query = "What is Ailoy?";
  const items = await vs.retrieve(query, 5);

  // Augment user query
  const prompt = `
    Based on the provided contexts, try to answer user' question.
    Context: ${items.map((item) => item.document)}
    Question: ${query}
  `;

  // Invoke agent
  for await (const resp of agent.run(prompt)) {
    process.stdout.write(resp.content);
  }
  process.stdout.write("\n");
}
```

</TabItem>
</CodeTabs>

> **Tip:** For best results, ensure your documents are chunked semantically
> (e.g., by paragraphs or sections).
